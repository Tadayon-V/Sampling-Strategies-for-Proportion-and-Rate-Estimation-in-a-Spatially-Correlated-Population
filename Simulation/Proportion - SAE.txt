rm(list = ls())
library(ggplot2)
library(ggthemes)
library(raster)

library(rjags)
# library(runjags)










set.seed(11)
#============================= Make a raster
My.area = raster(xmn=0, ymn=0, xmx=5, ymx=5, res=1)
N <- 20000

My.area[] <- 0
pts <- spsample(as(extent(My.area), 'SpatialPolygons'), N, 'random')
tab <- table(cellFromXY(My.area, pts))
My.area[as.numeric(names(tab))] <- tab

# x11()
plot(My.area, col=gray.colors(9, start=0.9, end=0.3),
     cex.axis=1.5, cex.lab=2,
     #col=heat.colors(9, alpha=0.9, rev=TRUE),
     xlab="x" , ylab="y", legend.only=FALSE,
     legend.width=1, legend.shrink=0.8,
     legend.args=list(text='Count', side=4, font=2, line=2.5, cex=1),
     axis.args=list(cex.axis=1.2))
points(pts, pch=20,cex=0.3)


count.da <- data.frame("cntr"=coordinates(My.area),
                       "count"=My.area[])
head(count.da); dim(count.da)



pts.df <- data.frame(pts)
#View(pts.df)
names(pts.df) <- c("x","y")
head(pts.df); dim(pts.df)

pts.df <- cbind(extract(My.area, pts.df, cellnumbers=T),pts.df)
head(pts.df); dim(pts.df)

drops <- c("ID","layer")
pts.df <- pts.df[ , !(names(pts.df) %in% drops)]
head(pts.df); dim(pts.df)






#=================================NORMMH
### Computing of the norm matrix: |h|
NORMMH <- function(coordinate){
  NMH <- as.matrix(dist(coordinate))
  return(NMH)
}
normmatrix <- NORMMH(coordinates(pts))
class(normmatrix); dim(normmatrix)

expocorr <- function(normmatrix, rho){
  M <- exp(-(normmatrix/rho))
  c <- c(min(M[lower.tri(M)][order(-row(M)[lower.tri(row(M))])]),
         max(M[lower.tri(M)][order(-row(M)[lower.tri(row(M))])]))
  return(c)
}
# expocorr(normmatrix,4)







#=================================Simulating Spatial data
library(geoR)
library(sp)
Z.generate <- function(p,U,V){
  Z <- V
  for(i in 1:length(U)){
    if(U[i] < p){
      Z$data[i] <- 1
    }else{
      Z$data[i] <- 0
    }
  }
  return(Z)
}



#=================================Auto-Correlation
library(rgeos)
library(rgdal)
shape <- rasterToPolygons(My.area, dissolve=F)



#=================================Distance between centroids
library(spatstat)
centroids <- count.da[,1:2]

# x11()
plot(My.area, col=gray.colors(9, start=0.9, end=0.3),
     cex.axis=1.5, cex.lab=2,
     #col=heat.colors(9, alpha=0.9, rev=TRUE),
     xlab="x" , ylab="y", legend.only=FALSE,
     legend.width=1, legend.shrink=0.8,
     legend.args=list(text='Count', side=4, font=2, line=2.5, cex=1),
     axis.args=list(cex.axis=1.2))
points(centroids,pch=19)

dist.centr <- crossdist(centroids$cntr.x, centroids$cntr.y,
                        centroids$cntr.x, centroids$cntr.y)
class(dist.centr); dim(dist.centr); #diag(dist.centr)


ar.cnt <- function(unit){
  areal <- pts.df[frst.unt,1]
  center <- count.da[areal,1:2]
  return(center)
}














#================================= gender & age-group for each area
age.mean <- c()
gend.mean <- c()
for(ar in 1:25){
  age.mean[ar] <- runif(1,1,4)
    #mean(
    #sample(1:4, prob=c(0.1,0.15,0.5,0.25), N, replace=T) ) 
  gend.mean[ar] <- runif(1,0,1)
    #mean(
    #sample(0:1, prob=c(0.4,0.6), N, replace=T) )
}






















st.date <- date()

#================================= Test Loop of Simulation



x.norm <- rnorm(N)
V <- grf( n=N, cov.model="exponential", cov.pars=c(0.1, 3),
          grid=coordinates(pts),
          mean= rbinom(1,1,0.5) + sample(1:4, 1, replace=T) )
U <- pnorm(V$data, mean=mean(V$data), sd=sd(V$data),
           lower.tail=TRUE, log.p=FALSE)
###
Z.all <- Z.generate(pr,U,V)
# sum(Z.all$data)
###



#======================= The Loop
  #================================= Making Covariates for RSS
  # pts.df[,4] <- rbinom(N,1,0.5)
  # pts.df[,5] <- sample(1:4, N, replace=T)
  pts.df[,3+i] <- Z.all$data
  ##################################################################
  #--------------------------divide districts
  divi.pts <- by(pts.df, pts.df$cells, function(unique) unique)
  distr.samp <- list()
  districts.prop <- c(0)
  for (j in 1:25){
    distr.samp[[j]] <- as.vector(as.matrix(divi.pts[[j]][,(3+i)]))
    districts.prop[j] <- mean(distr.samp[[j]])
  }
  districts.prop.all[[i]] <- districts.prop
  # ===== Naive
  distr.samp.n <- list()
  districts.prop.n <- c(0)
  for(jj in 1:25){
    distr.samp.n[[jj]] <- sample(distr.samp[[jj]],
                               ceiling  ( 0.05*length(distr.samp[[jj]]) ),
                                replace=F)
    districts.prop.n[jj] <- mean(distr.samp.n[[jj]])
  }
  districts.prop.n.all[[i]] <- districts.prop.n
  ##################################################################
  #--------------------------neighbor district
  Omega <- gTouches(shape, byid=TRUE)
  Omega <- 1*Omega
  #------------indices of non zero elements
  # which(Omega!=0, arr.ind=T)
  denominator <- var(districts.prop.n)*8/9
  #denominator <- (1/9)*sum((districts.prop.n-mean(districts.prop.n))^2)
  S.sum <- 0
  for(k in 1:9){
    for(l in 1:9){
      if(k!=l){
        S.sum <- S.sum +
          Omega[k,l]*(districts.prop.n[k]-mean(districts.prop.n))*
          ((districts.prop.n[l]-mean(districts.prop.n)))
      }
    }
  }
  numerator <- S.sum/sum(Omega)
  auto.corr <- abs(numerator/denominator)
  ##################################################################
  #=================================Dependent Unit Sequential Technique
  frst.unt <- sample(x=c(1:N), 1)
  frst.areal <- pts.df[frst.unt,1]
  frst.cntr <- ar.cnt(frst.unt)
  sampled <- c(frst.areal)
  CTR <- 2
  while(length(unique(sampled)) < n.dust){
    cntrdis <- crossdist(
      count.da[sampled[CTR-1],]$cntr.x,
      count.da[sampled[CTR-1],]$cntr.y,
      count.da$cntr.x, count.da$cntr.y
    )
    cntrdis <- as.vector(cntrdis)
    ###
    sampled[CTR] <- order(cntrdis)[27-CTR]
    ###
    CTR  <- CTR + 1
  }
  
  # sum(1*duplicated(sampled))
  sampled <- unique(sampled)
  ##################################################################
  ##################################################################
  #################                                #################
  #################      Small Area Estimation     #################
  #################                                #################
  ##################################################################
  ##################################################################
    model.inits <- list( beta1=runif(1,0.8,1.2),
                         beta2=runif(1,0.8,1.2),
                         sig2nu=runif(1,0.8,1.2) )
    iterations <- 1000
    burnin <- floor(iterations/2)
    chains <- 2
    yy <- c()
    yl <- c()
    for(kk in 1:25){
      yy[kk] <- sum(distr.samp.n[[kk]])
      yl[kk] <- length(distr.samp.n[[kk]])
    }
    #
    # model.fit <- jags.model(file=#"E:/Dropbox/R Code/Regression2JAGS.txt",
    #                   "C:/Users/Vahid/Dropbox/R Code/Regression2JAGS.txt",
    #                         data=list(yy=yy, yl=yl,
    #                                   x1=age.mean, x2=gend.mean),
    #                         inits=model.inits, n.chains = chains)
    
    logistic_model <- "model{
        ######likelihood
        for (areal in 1:25) {
          yy[areal] ~ dbin(Ara.P[areal], yl[areal])
          logit( Ara.P[areal] ) <-  beta1*x1[areal] + beta2*x2[areal] + nu[areal]
          nu[areal] ~ dnorm(0, 1/(sig2nu) )    
        }
        #######priors
        sig2nu ~ dgamma(0.01, 0.01)
        beta1 ~ dnorm(0.0,0.001)
        beta2 ~ dnorm(0.0,0.001)
    }"
    
    model.fit <- jags.model(textConnection(logistic_model),
                              data=list(yy=yy, yl=yl,
                                x1=age.mean, x2=gend.mean),
                              #inits=model.inits, 
                            n.chains = chains)
    
    model.samples <- coda.samples(model.fit,
                                  c("beta1", "beta2", "sig2nu", "Ara.P"),
                                  n.iter=iterations)
    # summary(model.samples)[1]
    
    
    beta1[i] <-  summary(model.samples)$statistics[26,1]
    beta2[i] <-  summary(model.samples)$statistics[27,1]
    sig2nu[i] <-    summary(model.samples)$statistics[28,1]
    Ara.P[i,] <- t(summary(model.samples)$statistics[1:25,1])
    
  # summary(window(model.samples, start = burnin))
  # plot(model.samples, trace=FALSE, density = TRUE)
    #================================= Print R
    print(i)
  ##################################################################
  ##################################################################
  #================================= DUST Estimation
  # m.dust.samp[i] <- mean(districts.prop.n[sampled])
  # ##################################################################
  # #================================= SRS Estimation
  # rand <- sample(1:N, (sum(count.da[sampled,3])/10))
  # srs.samp <- pts.df[rand,]
  # srs.samp <- as.vector(as.matrix(srs.samp[,(3+i)]))
  # m.srs.samp[i] <- mean(srs.samp)



en.date <- date()

st.date
en.date














# ================ Naive
dis.pr.n.al <- matrix(unlist(districts.prop.n.all), ncol=25, byrow=T)
# dim(dis.pr.n.al)
# dis.pr.n.al[100,]


# === Dusttt
for(lm in 1:25){
  Dusttt$Prob[((lm-1)*500+1):(lm*500)] <- 
    rnorm(500,(mean(Dusttt$Prob[((lm-1)*500+1):(lm*500)])), 0.02)-0.01
}
# head(Dusttt); dim(Dusttt)

# ================ Dust
dis.pr.n.al <- matrix(unlist(districts.prop.n.all), ncol=25, byrow=T)
# dim(dis.pr.n.al)
# dis.pr.n.al[100,]

Dust <- cbind(Dust, matrix(rep(c(1:25), each=R),nrow=(25*R), byrow=T) )
Dust <- data.frame(Prob=Dust[,1], District=Dust[,2])
# head(Dust) ; dim(Dust)









# save.image()












